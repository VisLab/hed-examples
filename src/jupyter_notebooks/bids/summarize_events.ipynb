{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Summarize the contents of the event files in a dataset.\n",
    "\n",
    "A first step in annotating a dataset is to find out what is in the dataset event files. Sometimes event files will have a few unexpected or incorrect codes. It is usually a good idea to find out what is actually in the dataset event files before starting the annotation process.\n",
    "\n",
    "This notebook traverses through the dataset and gathers the unique values for each column and number of times each value appears in the dataset.\n",
    "\n",
    "The setup requires the setting of the following variables for your dataset:\n",
    "\n",
    "| Variable | Purpose |\n",
    "| -------- | ------- |\n",
    "| dataset_path | Full path to root directory of dataset.|\n",
    "| exclude_dirs | List of directories to exclude when constructing the list of event files. |\n",
    "| `skip_columns`  |  List of column names in the `events.tsv` files to skip in the summary. |\n",
    "| `value_columns` | List of columns names in the `events.tsv` files that are just listed with element counts. |\n",
    "\n",
    "For large datasets, you will want to be sure to skip columns such as `onset` and `sample`, since the summary produces counts of the number of times each unique value appears somewhere in an event file.\n",
    "\n",
    "The notebook creates a `TabularSummary` object to handle the summarization.\n",
    "\n",
    "The example below uses a\n",
    "[small version](https://github.com/hed-standard/hed-examples/tree/main/datasets/eeg_ds003645s_hed)\n",
    "of the Wakeman-Hanson face-processing dataset available on openNeuro as\n",
    "[ds003645](https://openneuro.org/datasets/ds003645/versions/2.0.0)\n",
    "which is distributed as part of this dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T11:20:04.561801Z",
     "start_time": "2024-09-26T11:20:03.168288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from hed.tools import TabularSummary, get_file_list\n",
    "\n",
    "# Variables to set for the specific dataset\n",
    "dataset_path =  os.path.realpath('../../../datasets/eeg_ds003645s_hed')\n",
    "output_path = ''\n",
    "name = 'eeg_ds003645s_hed'\n",
    "exclude_dirs = ['stimuli', 'code', 'derivatives', 'sourcedata', 'phenotype']\n",
    "skip_columns = [\"onset\", \"duration\", \"sample\", \"trial\", \"response_time\"]\n",
    "value_columns = [\"stim_file\"]\n",
    "\n",
    "# Construct the file dictionary for the BIDS event files\n",
    "event_files = get_file_list(dataset_path, extensions=[\".tsv\"], name_suffix=\"_events\", exclude_dirs=exclude_dirs)\n",
    "print(f\"Processing {len(event_files)} files...\")\n",
    "# Create a tabular summary object\n",
    "tab_sum = TabularSummary(value_cols=value_columns, skip_cols=skip_columns, name=name)\n",
    "\n",
    "# Update the tabular summary with the information from each event file\n",
    "print(\"Updating the summaries\")\n",
    "for events in event_files:\n",
    "    tab_sum.update(events)\n",
    "    \n",
    "# Save or print\n",
    "if output_path:\n",
    "    with open(output_path, 'w') as fp:\n",
    "        fp.write(f\"{tab_sum}\")\n",
    "else:\n",
    "    print(f\"{tab_sum}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6 files...\n",
      "Updating the summaries\n",
      "Summary for column dictionary eeg_ds003645s_hed:\n",
      "   Categorical columns (5):\n",
      "      event_type (8 distinct values):\n",
      "         double_press: [1, 1]\n",
      "         left_press: [83, 4]\n",
      "         right_press: [168, 6]\n",
      "         setup_right_sym: [6, 6]\n",
      "         show_circle: [316, 6]\n",
      "         show_cross: [310, 6]\n",
      "         show_face: [310, 6]\n",
      "         show_face_initial: [6, 6]\n",
      "      face_type (4 distinct values):\n",
      "         famous_face: [108, 6]\n",
      "         nan: [884, 6]\n",
      "         scrambled_face: [103, 6]\n",
      "         unfamiliar_face: [105, 6]\n",
      "      rep_lag (12 distinct values):\n",
      "         1.0: [77, 6]\n",
      "         10.0: [15, 6]\n",
      "         11.0: [13, 5]\n",
      "         12.0: [9, 5]\n",
      "         13.0: [7, 6]\n",
      "         14.0: [6, 4]\n",
      "         15.0: [2, 2]\n",
      "         6.0: [1, 1]\n",
      "         7.0: [2, 2]\n",
      "         8.0: [6, 4]\n",
      "         9.0: [10, 6]\n",
      "         nan: [1052, 6]\n",
      "      rep_status (4 distinct values):\n",
      "         delayed_repeat: [71, 6]\n",
      "         first_show: [168, 6]\n",
      "         immediate_repeat: [77, 6]\n",
      "         nan: [884, 6]\n",
      "      value (15 distinct values):\n",
      "         0: [316, 6]\n",
      "         1: [310, 6]\n",
      "         13: [56, 6]\n",
      "         14: [24, 6]\n",
      "         15: [25, 6]\n",
      "         17: [54, 6]\n",
      "         18: [32, 6]\n",
      "         19: [17, 6]\n",
      "         256: [83, 4]\n",
      "         3: [6, 6]\n",
      "         4096: [168, 6]\n",
      "         4352: [1, 1]\n",
      "         5: [58, 6]\n",
      "         6: [21, 6]\n",
      "         7: [29, 6]\n",
      "   Value columns (1):\n",
      "      stim_file: [1200, 6]\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
